# Opossum Performance Benchmarking

> Professional benchmarking strategy for the Opossum file system-based event store library.

[![Status](https://img.shields.io/badge/status-ready-brightgreen)]()
[![Phase](https://img.shields.io/badge/phase-planning_complete-blue)]()
[![Framework](https://img.shields.io/badge/framework-BenchmarkDotNet-orange)]()

---

## ðŸŽ¯ Quick Start

### For Developers (New to This)

```bash
# 1. Read the overview
Start â†’ docs/benchmarking/SUMMARY.md (10 minutes)

# 2. Understand patterns
Read â†’ docs/benchmarking/quick-reference.md (20 minutes)

# 3. Start implementing
Follow â†’ docs/benchmarking/implementation-checklist.md
```

### For Decision Makers

```bash
# Understand WHY and ROI
Read â†’ docs/benchmarking/why-benchmarking-matters.md (15 minutes)
```

### For Technical Leads

```bash
# Comprehensive strategy
Read â†’ docs/benchmarking/benchmarking-strategy.md (40 minutes)
```

---

## ðŸ“š Documentation

### Master Index
**[ðŸ“– INDEX.md](INDEX.md)** - Navigate all documentation

### Core Documents

| Document | Purpose | Audience | Time |
|----------|---------|----------|------|
| **[SUMMARY.md](SUMMARY.md)** | Planning complete overview | Everyone | 10 min |
| **[why-benchmarking-matters.md](why-benchmarking-matters.md)** | Context and ROI | Decision makers | 15 min |
| **[benchmarking-strategy.md](benchmarking-strategy.md)** | Comprehensive plan | Tech leads | 40 min |
| **[quick-reference.md](quick-reference.md)** | Patterns & examples | Developers | 20 min |
| **[implementation-checklist.md](implementation-checklist.md)** | Step-by-step guide | Implementers | 15 min |

### Project Documentation
**[ðŸ“˜ Benchmark Project README](../../tests/Opossum.BenchmarkTests/README.md)** - How to run benchmarks

---

## ðŸŽ“ What's Included

### 1. Comprehensive Strategy
- âœ… Critical performance areas identified
- âœ… 50+ benchmark scenarios planned
- âœ… Industry best practices (BenchmarkDotNet)
- âœ… 4-6 week implementation timeline
- âœ… Success criteria defined

### 2. Detailed Implementation Guide
- âœ… Phase-by-phase checklist
- âœ… Code templates and patterns
- âœ… Common pitfalls documented
- âœ… Validation requirements
- âœ… Quick command reference

### 3. Project Structure
- âœ… Benchmark project layout designed
- âœ… Helper classes planned
- âœ… Configuration standards defined
- âœ… CI/CD integration strategy

### 4. Performance Analysis
- âœ… Critical paths identified
- âœ… Bottleneck hypotheses
- âœ… Performance targets estimated
- âœ… Optimization roadmap

---

## ðŸ”¥ Critical Performance Areas

### Core Operations (Priority: CRITICAL)
- **AppendAsync** - Write throughput, latency, flush overhead
- **ReadAsync** - Query performance by type/tags/complexity
- **DCB Validation** - Optimistic concurrency under load
- **Concurrency** - Thread contention, lock analysis

### Storage Layer (Priority: MEDIUM)
- **Serialization** - JSON performance
- **Indexing** - Tag/type index operations
- **Ledger** - Sequence position management
- **File I/O** - Read/write performance, parallel reads

### Advanced Features (Priority: MEDIUM/LOW)
- **Projections** - Build performance, query latency
- **Mediator** - Dispatch overhead
- **End-to-End** - Real-world scenarios

---

## ðŸ“Š Example Benchmark

```csharp
using Opossum.Core;
using BenchmarkDotNet.Attributes;

namespace Opossum.BenchmarkTests.Core;

/// <summary>
/// Benchmarks for AppendAsync operation.
/// Measures write throughput and flush overhead.
/// </summary>
[Config(typeof(OpossumBenchmarkConfig))]
[MemoryDiagnoser]
public class AppendBenchmarks
{
    private IEventStore _eventStore = null!;
    private SequencedEvent[] _events = null!;

    [GlobalSetup]
    public void Setup()
    {
        _eventStore = CreateEventStore();
        _events = GenerateEvents(1);
    }

    [Benchmark(Baseline = true)]
    public async Task SingleEventAppend_NoFlush()
    {
        await _eventStore.AppendAsync(_events, null);
    }

    [Benchmark]
    public async Task SingleEventAppend_WithFlush()
    {
        await _eventStore.AppendAsync(_events, null);
    }
}
```

**Expected Output:**
```
| Method                     | Mean     | P95      | Allocated |
|--------------------------- |---------:|---------:|----------:|
| SingleEventAppend_NoFlush  | 0.823 ms | 0.901 ms | 2.1 KB    |
| SingleEventAppend_WithFlush| 6.234 ms | 6.789 ms | 2.1 KB    |
```

**Insight:** Flush adds ~5ms overhead on SSD

---

## ðŸš€ Implementation Phases

### Phase 1: Foundation (Week 1)
- âœ… Set up BenchmarkDotNet project
- âœ… Create shared configuration
- âœ… Implement data generators
- âœ… Write first benchmark (AppendAsync baseline)
- âœ… Validate execution
- âœ… Document baseline results

### Phase 2: Core Operations (Week 2)
- AppendBenchmarks (all scenarios)
- ReadBenchmarks (all scenarios)
- QueryBenchmarks (complex queries)

### Phase 3: Storage Layer (Week 3)
- SerializationBenchmarks
- IndexBenchmarks
- LedgerBenchmarks
- FileSystemBenchmarks

### Phase 4: Advanced Features (Week 4)
- ProjectionBuildBenchmarks
- ProjectionQueryBenchmarks
- MediatorBenchmarks
- ConcurrencyBenchmarks

### Phase 5: Analysis & Optimization (Week 5+)
- Analyze results
- Identify optimization opportunities
- Implement optimizations
- Re-benchmark

---

## ðŸ“ˆ Expected Findings

### Performance Targets (To Be Validated)

| Operation | Target P95 | Notes |
|-----------|------------|-------|
| Append (no flush) | < 1ms | In-memory operations |
| Append (flush) | < 10ms | SSD flush overhead |
| Batch 100 (flush) | < 50ms | ~0.5ms per event |
| Query 1K by tag | < 5ms | Index lookup + reads |
| Query 10K by tag | < 50ms | Linear scaling |
| Projection 10K | < 1s | Reasonable rebuild |

### Critical Questions to Answer

1. **"How fast can I append events?"**
   - Single vs batch performance
   - Flush overhead quantification
   - Throughput limits

2. **"Should I enable FlushEventsImmediately?"**
   - Performance vs durability trade-off
   - SSD vs HDD comparison
   - When to batch

3. **"How many events can I query efficiently?"**
   - Scaling characteristics
   - Index efficiency
   - When to use projections

4. **"Will parallel reads help?"**
   - Speedup at different event counts
   - Optimal parallelism degree
   - Memory overhead

---

## ðŸ› ï¸ Tools & Technologies

- **BenchmarkDotNet** - Industry-standard .NET benchmarking
- **.NET 10** - Latest framework
- **Memory Diagnoser** - Track allocations
- **Threading Diagnoser** - Analyze contention
- **Markdown/HTML/CSV Exporters** - Multiple output formats

---

## ðŸ“ Documentation Standards

### Every Benchmark Must Have:
- âœ… Summary XML comment
- âœ… Scenarios documented
- âœ… GlobalSetup for initialization
- âœ… GlobalCleanup for temp files
- âœ… Baseline comparison (where applicable)
- âœ… MemoryDiagnoser attribute

### Every Result Set Must Have:
- âœ… Environment documentation (CPU, RAM, Storage)
- âœ… Key findings summary
- âœ… Performance insights
- âœ… Recommendations

---

## âš ï¸ Best Practices

### âœ… DO:
- Run in Release mode
- Use `[GlobalSetup]` for expensive initialization
- Return or consume benchmark results
- Clean up temp files
- Use realistic test data
- Document findings

### âŒ DON'T:
- Include setup in benchmark methods
- Block on async with `.Wait()`
- Use hardcoded paths
- Forget cleanup
- Optimize before measuring
- Run in Debug mode

---

## ðŸ” How to Use This Repository

### 1. **If You're New to Benchmarking**
```bash
# Start here
1. Read docs/benchmarking/SUMMARY.md
2. Read docs/benchmarking/quick-reference.md
3. Follow docs/benchmarking/implementation-checklist.md Phase 1
```

### 2. **If You're Writing Benchmarks**
```bash
# Quick reference
1. Use patterns from docs/benchmarking/quick-reference.md Section 8
2. Follow checklist in docs/benchmarking/implementation-checklist.md
3. Validate with: dotnet run -c Release --job dry
```

### 3. **If You're Running Benchmarks**
```bash
# See project README
1. Read tests/Opossum.BenchmarkTests/README.md
2. Run: dotnet run -c Release --project tests/Opossum.BenchmarkTests
3. Interpret results using docs/benchmarking/quick-reference.md Section 9
```

### 4. **If You're Analyzing Results**
```bash
# Results interpretation
1. Check tests/Opossum.BenchmarkTests/README.md â†’ Understanding Results
2. Use templates from docs/benchmarking/quick-reference.md Section 12
3. Document in docs/benchmarking/results/
```

---

## ðŸ“Š Success Criteria

Benchmarking is successful when:

1. âœ… All critical operations have baseline metrics
2. âœ… Performance bottlenecks are identified
3. âœ… Results are reproducible (Â±5% variance)
4. âœ… Documentation is comprehensive
5. âœ… Benchmarks run in CI/CD
6. âœ… Team uses benchmarks to guide optimization decisions

---

## ðŸ¤ Contributing

### Adding a New Benchmark

1. Choose the appropriate category (Core/Storage/Advanced)
2. Follow the template in `quick-reference.md` Appendix A
3. Use `OpossumBenchmarkConfig`
4. Add `[MemoryDiagnoser]`
5. Test with `--job dry`
6. Document findings

See `tests/Opossum.BenchmarkTests/README.md` â†’ Contributing section.

---

## ðŸ“… Timeline

**Planning:** âœ… Complete (2025-01-28)  
**Phase 1 (Foundation):** ðŸ”² Not started (1 week)  
**Phase 2 (Core):** ðŸ”² Not started (1 week)  
**Phase 3 (Storage):** ðŸ”² Not started (1 week)  
**Phase 4 (Advanced):** ðŸ”² Not started (1 week)  
**Phase 5 (Optimization):** ðŸ”² Not started (2+ weeks)  

**Total Estimated Time:** 4-6 weeks

---

## ðŸŽ¯ Next Steps

### Immediate Actions:

1. **Review Documentation** (1 hour)
   - Read SUMMARY.md
   - Skim strategy document
   - Review quick-reference patterns

2. **Start Phase 1** (1-2 days)
   - Update project files
   - Create infrastructure
   - Write first benchmark
   - Validate execution

3. **Document Results**
   - Record baseline metrics
   - Identify first bottleneck
   - Plan optimization

---

## ðŸ“ž Support & Questions

**Documentation:** All questions should be answered in the docs  
**Issues:** Create GitHub issue if documentation is unclear  
**Improvements:** Submit PR with documentation updates  

---

## ðŸ“œ License

Same as Opossum project (see root LICENSE file).

---

## âœ¨ Summary

You have a **professional, comprehensive benchmarking strategy** that:

- âœ… Follows .NET industry standards (BenchmarkDotNet)
- âœ… Is tailored to Opossum's file-based architecture
- âœ… Covers all critical performance areas (50+ scenarios)
- âœ… Provides step-by-step implementation guidance
- âœ… Includes best practices and anti-patterns
- âœ… Sets clear success criteria
- âœ… Enables data-driven optimization

**Status:** âœ… Planning Complete  
**Ready For:** Implementation  
**Next Action:** Follow Phase 1 checklist or request AI implementation

---

**Created:** 2025-01-28  
**Last Updated:** 2025-01-28  
**Branch:** feature/benchmark  
**Status:** Planning Complete âœ…

---

**[ðŸ“– See INDEX.md for full documentation navigation](INDEX.md)**
