# Opossum Benchmarking - Quick Reference

## ğŸ“Š What We're Benchmarking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Opossum Event Store                           â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  AppendAsync â”‚  â”‚  ReadAsync   â”‚  â”‚  Projections â”‚          â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚          â”‚
â”‚  â”‚  Write Path  â”‚  â”‚  Query Path  â”‚  â”‚  Read Models â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                  â”‚                  â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                            â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚            Storage Layer (File System)            â”‚          â”‚
â”‚  â”‚                                                    â”‚          â”‚
â”‚  â”‚  â”œâ”€ EventFileManager (event files)                â”‚          â”‚
â”‚  â”‚  â”œâ”€ IndexManager (type/tag indices)               â”‚          â”‚
â”‚  â”‚  â”œâ”€ LedgerManager (sequence positions)            â”‚          â”‚
â”‚  â”‚  â””â”€ JsonEventSerializer (serialization)           â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Critical Performance Paths

### 1. **Write Path** (AppendAsync)
```
User â†’ AppendAsync
  â†“
Validate Input
  â†“
Check DCB Condition (optional) â”€â”€â”€â”€â†’ Query Index âš ï¸ HOT PATH
  â†“
Allocate Sequence Position â”€â”€â”€â”€â”€â”€â”€â”€â†’ Read/Write Ledger âš ï¸ HOT PATH
  â†“
Serialize Events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ JSON Serialization âš ï¸ HOT PATH
  â†“
Write Event Files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ File I/O + Flush âš ï¸ HOT PATH
  â†“
Update Indices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Index Write âš ï¸ HOT PATH
  â†“
Update Ledger â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Ledger Write + Flush âš ï¸ HOT PATH
  â†“
Return Success
```

**Benchmark Priority:** ğŸ”¥ CRITICAL

**Key Metrics:**
- Latency: Mean, P95, P99
- Throughput: Events/second
- Memory: Allocations per append
- Concurrency: Lock contention

---

### 2. **Read Path** (ReadAsync)
```
User â†’ ReadAsync(query)
  â†“
Parse Query
  â†“
For each QueryItem:
  â†“
  Get Positions by EventType â”€â”€â”€â”€â†’ Index Lookup âš ï¸ HOT PATH
  â†“
  Get Positions by Tags â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Index Lookup âš ï¸ HOT PATH
  â†“
  Intersect/Union positions
  â†“
Sort Positions
  â†“
Read Event Files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ File I/O (parallel) âš ï¸ HOT PATH
  â†“
Deserialize Events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ JSON Deserialization âš ï¸ HOT PATH
  â†“
Apply ReadOptions (order)
  â†“
Return Events
```

**Benchmark Priority:** ğŸ”¥ CRITICAL

**Key Metrics:**
- Query latency vs dataset size
- Index efficiency (selectivity)
- Parallel read speedup
- Memory per query

---

### 3. **Projection Build Path**
```
ProjectionManager â†’ BuildProjection
  â†“
Load Checkpoint
  â†“
Query Events (by tags/types) â”€â”€â”€â”€â†’ ReadAsync âš ï¸ HOT PATH
  â†“
For each event:
  â†“
  Apply to projection
  â†“
  Update checkpoint
  â†“
Save Projection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Serialization + File I/O
  â†“
Save Checkpoint
```

**Benchmark Priority:** ğŸŸ¡ MEDIUM

**Key Metrics:**
- Build time (total)
- Throughput (events/second)
- Memory usage during build

---

## ğŸ“ˆ Benchmark Scenarios Matrix

| Category | Scenario | Variables | Priority |
|----------|----------|-----------|----------|
| **Append** | Single event | flush on/off | ğŸ”¥ |
| | Batch (10, 100, 1000) | flush on/off | ğŸ”¥ |
| | With DCB validation | condition complexity | ğŸ”¥ |
| | Concurrent (2, 4, 8 threads) | thread count | ğŸ”¥ |
| **Read** | By event type | dataset size (100, 1K, 10K) | ğŸ”¥ |
| | By tags (AND) | tag count (1, 3, 5) | ğŸ”¥ |
| | By tags + type | dataset size | ğŸ”¥ |
| | Query.All() | dataset size | ğŸŸ¡ |
| | Parallel reads | enabled/disabled | ğŸ”¥ |
| **Serialization** | Serialize event | size (small, medium, large) | ğŸŸ¡ |
| | Deserialize event | size (small, medium, large) | ğŸŸ¡ |
| | With tags | tag count (0, 5, 10) | ğŸŸ¡ |
| **Index** | Add to type index | index size (100, 1K, 10K) | ğŸŸ¡ |
| | Add to tag index | tags per event (1, 5, 10) | ğŸŸ¡ |
| | Lookup by type | index size | ğŸ”¥ |
| | Lookup by tag | index size | ğŸ”¥ |
| **Ledger** | Get next position | cold/warm | ğŸŸ¡ |
| | Update position | flush on/off | ğŸŸ¡ |
| **Projections** | Build projection | event count (100, 1K, 10K) | ğŸŸ¡ |
| | Query projection | projection count | ğŸŸ¢ |
| **Mediator** | Dispatch command | handler complexity | ğŸŸ¢ |
| **Concurrency** | Parallel appends | thread count (2, 4, 8, 16) | ğŸ”¥ |
| | Mixed workload | read/write ratio | ğŸ”¥ |

**Legend:**  
ğŸ”¥ Critical - Always benchmark  
ğŸŸ¡ Medium - Benchmark for optimization  
ğŸŸ¢ Low - Benchmark for completeness  

---

## ğŸ­ Sample Benchmark Patterns

### Pattern 1: Simple Operation Benchmark
```csharp
[Config(typeof(OpossumBenchmarkConfig))]
[MemoryDiagnoser]
public class AppendBenchmarks
{
    private IEventStore _eventStore = null!;
    private SequencedEvent[] _events = null!;

    [GlobalSetup]
    public void Setup()
    {
        // One-time expensive setup
        _eventStore = CreateEventStore();
        _events = GenerateEvents(100);
    }

    [Benchmark]
    public async Task SingleEventAppend()
    {
        // Only measure this operation
        await _eventStore.AppendAsync([_events[0]], null);
    }

    [GlobalCleanup]
    public void Cleanup()
    {
        // Clean up resources
        DeleteTempFiles();
    }
}
```

### Pattern 2: Parameterized Benchmark
```csharp
[Config(typeof(OpossumBenchmarkConfig))]
[MemoryDiagnoser]
public class ReadBenchmarks
{
    [Params(100, 1_000, 10_000)]
    public int EventCount;

    [Params(true, false)]
    public bool ParallelReads;

    private IEventStore _eventStore = null!;
    private Query _query = null!;

    [GlobalSetup]
    public void Setup()
    {
        _eventStore = CreateEventStore();
        SeedEvents(EventCount);
        _query = CreateQuery();
    }

    [Benchmark]
    public async Task<SequencedEvent[]> QueryByTag()
    {
        return await _eventStore.ReadAsync(_query, null);
    }
}
```

### Pattern 3: Baseline Comparison
```csharp
[Config(typeof(OpossumBenchmarkConfig))]
[MemoryDiagnoser]
public class FlushBenchmarks
{
    private IEventStore _noFlush = null!;
    private IEventStore _withFlush = null!;
    private SequencedEvent[] _events = null!;

    [GlobalSetup]
    public void Setup()
    {
        _noFlush = CreateEventStore(flush: false);
        _withFlush = CreateEventStore(flush: true);
        _events = GenerateEvents(1);
    }

    [Benchmark(Baseline = true)]
    public async Task AppendNoFlush()
    {
        await _noFlush.AppendAsync(_events, null);
    }

    [Benchmark]
    public async Task AppendWithFlush()
    {
        await _withFlush.AppendAsync(_events, null);
    }
}
```

### Pattern 4: Concurrency Benchmark
```csharp
[Config(typeof(OpossumBenchmarkConfig))]
[MemoryDiagnoser]
[ThreadingDiagnoser]
public class ConcurrencyBenchmarks
{
    [Params(1, 2, 4, 8)]
    public int ThreadCount;

    private IEventStore _eventStore = null!;

    [GlobalSetup]
    public void Setup()
    {
        _eventStore = CreateEventStore();
    }

    [Benchmark]
    public async Task ConcurrentAppends()
    {
        var tasks = new Task[ThreadCount];
        for (int i = 0; i < ThreadCount; i++)
        {
            var events = GenerateEvents(10);
            tasks[i] = _eventStore.AppendAsync(events, null);
        }
        await Task.WhenAll(tasks);
    }
}
```

---

## ğŸ“Š Expected Output Format

### Console Output (Summary)
```
BenchmarkDotNet v0.14.0, Windows 11
Intel Core i7-12700K CPU 3.60GHz, 1 CPU, 20 logical and 12 physical cores
.NET SDK 10.0.0

| Method               | EventCount | Mean       | StdDev   | P95        | Allocated |
|--------------------- |----------- |-----------:|---------:|-----------:|----------:|
| SingleEventAppend    | 1          | 0.823 ms   | 0.045 ms | 0.901 ms   | 2.1 KB    |
| BatchAppend          | 10         | 6.234 ms   | 0.312 ms | 6.789 ms   | 18.7 KB   |
| BatchAppend          | 100        | 58.123 ms  | 2.451 ms | 62.345 ms  | 172.3 KB  |
```

### Exported Files
```
BenchmarkDotNet.Artifacts/
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ AppendBenchmarks-report.html
â”‚   â”œâ”€â”€ AppendBenchmarks-report.md
â”‚   â”œâ”€â”€ AppendBenchmarks-measurements.csv
â”‚   â””â”€â”€ AppendBenchmarks-report.json
â””â”€â”€ logs/
    â””â”€â”€ AppendBenchmarks.log
```

---

## ğŸ” Key Metrics Explained

### Latency Metrics
- **Mean:** Average time per operation
- **StdDev:** Standard deviation (consistency)
- **Median (P50):** 50% of operations finish faster
- **P95:** 95% of operations finish faster (good SLA target)
- **P99:** 99% of operations finish faster (outlier detection)

### Throughput Metrics
- **ops/sec:** Operations per second
- **events/sec:** Events processed per second (for batch operations)

### Memory Metrics
- **Allocated:** Total memory allocated per operation
- **Gen0/1/2:** Garbage collection impact

### Threading Metrics
- **Completed Work Items:** Work done by thread pool
- **Lock Contentions:** How often threads waited for locks

---

## âš ï¸ Common Pitfalls

### âŒ DON'T
```csharp
// 1. Dead code elimination
[Benchmark]
public void Wrong()
{
    var result = ExpensiveOperation(); // Result unused - may be optimized away!
}

// 2. Including setup in benchmark
[Benchmark]
public void Wrong2()
{
    var eventStore = CreateEventStore(); // âŒ Should be in [GlobalSetup]
    eventStore.AppendAsync(events, null);
}

// 3. Blocking async
[Benchmark]
public void Wrong3()
{
    _eventStore.AppendAsync(events, null).Wait(); // âŒ Use Task return type
}
```

### âœ… DO
```csharp
// 1. Return or consume result
[Benchmark]
public SequencedEvent[] Correct()
{
    return ExpensiveOperation(); // âœ… Result is used
}

// 2. Setup in GlobalSetup
[GlobalSetup]
public void Setup()
{
    _eventStore = CreateEventStore(); // âœ…
}

[Benchmark]
public Task Correct2()
{
    return _eventStore.AppendAsync(_events, null); // âœ…
}
```

---

## ğŸš€ Quick Start Commands

```bash
# 1. Navigate to benchmark project
cd tests/Opossum.BenchmarkTests

# 2. Build in Release mode (required!)
dotnet build -c Release

# 3. Run all benchmarks (slow - grab coffee â˜•)
dotnet run -c Release

# 4. Run single benchmark class (faster)
dotnet run -c Release --filter *AppendBenchmarks*

# 5. Dry run to validate (fast)
dotnet run -c Release --job dry

# 6. List available benchmarks
dotnet run -c Release --list flat
```

---

## ğŸ“š Decision Tree: Which Benchmark Pattern?

```
Is it a core IEventStore operation?
  â”œâ”€ Yes â†’ Create dedicated benchmark class
  â”‚         Example: AppendBenchmarks, ReadBenchmarks
  â”‚
  â””â”€ No â†’ Is it a helper/utility component?
      â”œâ”€ Yes â†’ Group with related benchmarks
      â”‚         Example: SerializationBenchmarks for JsonEventSerializer
      â”‚
      â””â”€ No â†’ Is it testing configuration impact?
          â”œâ”€ Yes â†’ Use parameterized benchmark with [Params]
          â”‚         Example: [Params(true, false)] for FlushImmediately
          â”‚
          â””â”€ No â†’ Is it testing concurrency?
              â”œâ”€ Yes â†’ Use ThreadingDiagnoser + parallel Tasks
              â”‚         Example: ConcurrencyBenchmarks
              â”‚
              â””â”€ Complex scenario â†’ Create scenario-specific benchmark
                    Example: ProjectionBuildBenchmarks
```

---

## ğŸ“ Results Documentation Template

```markdown
# Benchmark Results - [Date]

## Environment
- **OS:** Windows 11 Pro 23H2
- **CPU:** Intel Core i7-12700K @ 3.60GHz (12C/20T)
- **RAM:** 32GB DDR4-3200
- **Storage:** Samsung 980 Pro 1TB NVMe SSD
- **.NET:** 10.0.0

## Summary

[Brief overview of what was benchmarked and key findings]

## AppendAsync Performance

| Scenario | Mean | P95 | P99 | Allocated |
|----------|------|-----|-----|-----------|
| Single (no flush) | 0.8ms | 1.2ms | 1.5ms | 2.1KB |
| Single (flush) | 6.2ms | 7.8ms | 9.1ms | 2.1KB |
| Batch 100 (flush) | 58ms | 65ms | 72ms | 172KB |

### Key Insights
1. **Flush overhead:** ~5ms per event on NVMe SSD
2. **Batching efficiency:** 100 events take 58ms = 0.58ms/event (better than single)
3. **Memory:** Linear scaling with event count

## ReadAsync Performance

[Similar table and insights]

## Recommendations

1. **For high throughput:** Disable flush or use batching
2. **For durability:** Keep flush enabled (default)
3. **For queries:** Tag indices perform well up to 10K events

## Detailed Results

See attached:
- `AppendBenchmarks-report.html`
- `AppendBenchmarks-measurements.csv`
```

---

**Last Updated:** 2025-01-28  
**Status:** Ready for Implementation  
**Next Steps:** Follow implementation-checklist.md Phase 1
