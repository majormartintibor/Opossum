# Opossum 0.5.0 — Release Roadmap

> **Status:** Planning
> **Target release:** 0.5.0
> **Builds on:** 0.4.0 (cross-process append safety — ADR-005)

This document captures improvements planned for the 0.5.0 milestone.

Items 2, 3, and 4 (write throughput optimisations A, B, E) were originally scoped for
0.4.0 but were deferred to keep that release tightly focused on the ADR-005 correctness
fix. The full research and design rationale lives in
`docs/analysis/throughput-research-and-improvement-paths.md` and
`docs/future-plans/0.4.0-roadmap.md#2-write-throughput-optimization-ab-e-under-discussion`.

Item 1 (`ReflectionMessageHandler` delegate cache) was also deferred from 0.4.0.

---

## Overview

| # | Feature | Breaking? | Effort |
|---|---------|-----------|--------|
| 1 | [Cache compiled delegate in `ReflectionMessageHandler`](#1-cache-compiled-delegate-in-reflectionmessagehandler) | No | Medium |
| 2 | [Option A — Append-only index files](#2-option-a--append-only-index-files) | Yes (index format) | Low |
| 3 | [Option B — In-memory index cache](#3-option-b--in-memory-index-cache) | No | Medium |
| 4 | [Option E — Implicit ledger](#4-option-e--implicit-ledger) | Yes (ledger removed) | Low–Medium |

---

## 1. Cache Compiled Delegate in `ReflectionMessageHandler`

### Why deferred from 0.4.0

0.4.0 bandwidth is fully occupied by ADR-005 (cross-process lock) and the A+B+E
storage-layer throughput work. The `ReflectionMessageHandler` optimisation does not
interact with either of those changes and carries non-trivial implementation risk
in edge cases (generic handlers, static handlers, `Task<T>` return types). Deferring
it preserves a focused 0.4.0 scope without any loss of function.

### Current state

`ReflectionMessageHandler.HandleAsync` dispatches every message via `MethodInfo.Invoke`:

```csharp
result = _method.Invoke(handlerInstance, args);
```

`_method` and `_parameters` are stored at construction time, so the handler avoids
repeated `GetMethod` / `GetParameters` lookups. However, `MethodInfo.Invoke` itself
still pays a per-call price:

- **Boxing** — value-type arguments are boxed into `object?[]` on every dispatch.
- **Security and visibility checks** — the CLR re-validates accessibility on each
  invocation unless the method was explicitly JIT-compiled into an open delegate.
- **`TargetInvocationException` wrapping** — exceptions thrown by the handler are
  wrapped and must be explicitly unwrapped, adding a catch block to the hot path.
- **No inlining** — the JIT cannot inline through a reflection call site.

For low-throughput mediator usage (e.g. one command per HTTP request) this overhead is
negligible. For high-throughput scenarios — batch processing, event replay driving
mediator dispatch, or benchmarks comparing Opossum to other mediator libraries — the
`Invoke` overhead becomes a measurable bottleneck.

### Why this matters

Every `await mediator.SendAsync(command)` call currently pays `MethodInfo.Invoke` overhead.
At 10,000 commands/second — plausible for a batch-processing use case — the per-call
overhead accumulates. A compiled open delegate eliminates boxing, removes the `Invoke`
trampoline, and lets the JIT inline the async state machine setup.

The improvement is especially visible in the replay scenario introduced by 0.3.0's
streaming reads: a projection that dispatches events through the mediator (for side-effect
processing) can hit tens of thousands of `HandleAsync` calls during a rebuild.

### Proposed implementation

Replace `MethodInfo.Invoke` with a compiled open delegate created once at construction
time and cached in a `readonly` field:

```csharp
// Compiled once per handler registration — paid at startup, not per-dispatch
private readonly Func<object?, object?[], object?> _compiled;

public ReflectionMessageHandler(Type handlerType, MethodInfo method)
{
    // ... existing null checks and field assignments ...

    _compiled = BuildCompiledDelegate(handlerType, method);
}

private static Func<object?, object?[], object?> BuildCompiledDelegate(
    Type handlerType, MethodInfo method)
{
    // instance parameter (null for static methods)
    var instanceParam = Expression.Parameter(typeof(object), "instance");
    // args array parameter
    var argsParam = Expression.Parameter(typeof(object[]), "args");

    var parameters = method.GetParameters();
    var argExpressions = new Expression[parameters.Length];
    for (int i = 0; i < parameters.Length; i++)
    {
        argExpressions[i] = Expression.Convert(
            Expression.ArrayIndex(argsParam, Expression.Constant(i)),
            parameters[i].ParameterType);
    }

    Expression? instanceExpr = method.IsStatic
        ? null
        : Expression.Convert(instanceParam, handlerType);

    var callExpr = Expression.Call(instanceExpr, method, argExpressions);

    Expression body = method.ReturnType == typeof(void)
        ? Expression.Block(callExpr, Expression.Constant(null, typeof(object)))
        : Expression.Convert(callExpr, typeof(object));

    return Expression.Lambda<Func<object?, object?[], object?>>(
        body, instanceParam, argsParam).Compile();
}
```

`HandleAsync` then replaces `_method.Invoke` with `_compiled(handlerInstance, args)`,
and the `TargetInvocationException` catch block is removed (compiled delegates rethrow
the original exception directly).

### Implementation considerations

- **Expression tree approach** is safer than `Delegate.CreateDelegate` for the general
  case because it handles static methods, instance methods, and different return types
  (`void`, `Task`, `Task<T>`) uniformly.
- **`async Task<T>` result extraction** — the existing `resultProperty?.GetValue(task)`
  reflection call for reading `Task<T>.Result` should also be replaced with a compiled
  accessor, or replaced by casting to `dynamic` / using `Task.ContinueWith` with typed
  continuations.
- **Startup cost** — `Expression.Compile()` is non-trivial but paid once per handler
  registration (at `AddMediator()` startup), not per dispatch. Acceptable trade-off.
- **Test coverage** — the existing `ReflectionMessageHandler` tests must be extended to
  cover static handlers, void-return handlers, and `Task<T>`-return handlers to guard
  against regressions in the compiled-delegate path.

### Breaking impact

None. This is a pure internal implementation change. The public `IMessageHandler` and
`Mediator` APIs are unchanged. Existing handler implementations require no modification.

### Performance expectation

| Scenario | Before | After (estimate) |
|----------|--------|-----------------|
| Single command dispatch | ~2–5 µs (`Invoke` overhead) | ~0.1–0.3 µs (delegate call) |
| 10,000 commands/s sustained | measurable CPU in profiler | negligible |
| Projection replay (streaming, 100k events) | `Invoke` in hot loop | inlined delegate |

Actual numbers should be verified with a `ReflectionMessageHandler` micro-benchmark
added to `Opossum.BenchmarkTests` before shipping this change.

---

## 2. Option A — Append-only index files

> Deferred from 0.4.0. Full design detail in `docs/future-plans/0.4.0-roadmap.md`
> and the throughput research in `docs/analysis/throughput-research-and-improvement-paths.md`.

### What it is

Replace the current full-rewrite index files (`.json`) with newline-delimited
append-only position lists (`.idx`):

```
# tagkey=tagvalue.idx
1
5
12
47
```

Append = `File.AppendAllTextAsync($"{position}\n")` — one write, no read, no temp file.
Read = `File.ReadAllLinesAsync(...)` — parse longs, deduplicate on load.

The cross-process lock from ADR-005 guarantees only one appender is active at a time,
making this safe. Concurrent readers use `FileShare.Read`, which is compatible with an
open append handle.

### Breaking change

Index file format changes from `.json` to `.idx`. Existing stores require a one-time
migration on first startup.

### Why ship before production stores exist

This is the only item with a **breaking store format change**. Shipping it while the
installed base is zero eliminates all future migration burden. Each release this is
deferred increases the migration cost for real users.

### Expected gain

~14% improvement on `FlushEventsImmediately = true` path (~92 → ~105 events/sec).

---

## 3. Option B — In-memory index cache

> Deferred from 0.4.0. Full design detail in `docs/future-plans/0.4.0-roadmap.md`
> and the throughput research in `docs/analysis/throughput-research-and-improvement-paths.md`.

### What it is

Load all tag and event-type indexes into memory at startup. All read queries and all
DCB condition checks are served from the in-memory cache (nanosecond lookups regardless
of store size). On append (inside the cross-process lock), update the in-memory cache
first, then flush only the M changed `.idx` files to disk before releasing the lock.

Cross-process staleness is detected in O(1) via an `AsOfPosition` counter: on every
lock acquisition the ledger position is already read; if it does not match the cache's
watermark, only the event files written since the last hold are read and only their
M index files are reloaded (typically 2–4 files per event).

**Depends on Option A** — the cache is keyed on the `.idx` files that Option A introduces.

### Breaking change

None. Transparent behaviour change.

### Expected gain

~19% improvement on top of Option A (~105 → ~125 events/sec on flush=true path).

---

## 4. Option E — Implicit ledger

> Deferred from 0.4.0 with decision still **pending**. The decision must be made
> before implementation begins. Full design detail in `docs/future-plans/0.4.0-roadmap.md`.

### What it is

Eliminate the `.ledger` file entirely. Position tracking becomes:

- **In-memory:** a `long` counter incremented inside the cross-process lock (never stale
  because only one writer holds the lock at a time)
- **On startup:** scan the events directory for the highest-numbered `*.json` file to
  initialise the counter
- **Crash recovery:** if the app crashes mid-append the temp file is cleaned up on
  restart; the startup scan finds the correct highest committed position

The second fsync (ledger) disappears. Only the event file fsync remains on the
flush=true path.

### Decision required before implementation

The correctness of replacing an explicit ledger with an implicit directory scan, the
crash-recovery edge cases (partial rename, interrupted rename), and the impact on
store observability must be explicitly approved before this option is confirmed.

### Breaking change

The `.ledger` file is removed from the store directory. Existing stores migrate
transparently — on first startup the position is re-derived from the directory scan.

### Expected gain

~48% improvement on top of Options A+B (~125 → ~185 events/sec on flush=true path).

---

## Combined performance expectation (Options A+B+E)

| Configuration | 0.4.0 baseline | After A+B | After A+B+E |
|---|---|---|---|
| No-flush (local) | ~205 events/sec | ~400–500 events/sec (~2.4×) | ~550–650 events/sec (~3×) |
| Flush=true (local) | ~92 events/sec | ~125–130 events/sec (~1.4×) | ~180–190 events/sec (~2×) |
| Flush=true (SMB LAN) | ~70–80 events/sec | ~90–100 events/sec (~1.3×) | ~120–140 events/sec (~1.7×) |
